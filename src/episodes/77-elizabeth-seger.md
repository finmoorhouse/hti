---
title: Elizabeth Seger on Open Source AI
audio: https://pinecast.com/listen/56712a2f-e38e-458f-bb2a-4274cef22da5.mp3
path: seger
number: 77
featuredImage: seger-share.png
backgroundImage: bazaar-3.png
date: 2024-07-24
---
[Elizabeth Seger](https://elizabethseger.com/) is the Director of Technology Policy at [Demos](https://demos.co.uk/our-approach/a-healthier-digital-ecosystem/), a cross-party UK think tank with a [program on trustworthy AI](https://demos.co.uk/our-approach/a-healthier-digital-ecosystem/). She was previously a researcher with Centre for the Governance of AI ([GovAI](https://www.governance.ai/)) in Oxford, and is an affiliate of the AI: Futures and Responsibility Project ([AI:FAR](https://www.ai-far.org/)) at the University of Cambridge.

{% aside %}

Note that this episode was recorded before the release of Meta's [Llama 3.1 family of models](https://ai.meta.com/blog/meta-llama-3-1/).

{% endaside %}

{% image "seger.webp" "Elizabeth Seger" %}

In this episode we talked about open source the risks and benefits of open source AI models. In particular, we discussed:

* What ‘open source’ really means
* What is (and isn't) open about ‘open source’ AI models
* How open source weights and code are useful for AI safety research
* How and when the costs of open sourcing frontier model weights might outweigh the benefits
* Analogies to ‘open sourcing nuclear designs’ and the [open science movement](https://en.wikipedia.org/wiki/Open_science)

{% aside %}

**Minor correction:** on the definition of open source AI, Elizabeth referenced an older version of the [definition maintained by OSI](https://opensource.org/deepdive/drafts) (roughly [version 0.0.3](https://opensource.org/deepdive/drafts/the-open-source-ai-definition-draft-v-0-0-3)). The current OSI definition (0.0.8) now does a much better job of delineating between different model components. Definition 0.0.8 identifies which components must be downloadable to meet the open-source definition, and which components are optional.

{% endaside %}

## Resources

Here's a markdown formatted list with appropriate descriptions for each link:

- [Report: Open-sourcing highly capable foundation models (Seger et al.)](https://www.governance.ai/research-paper/open-sourcing-highly-capable-foundation-models)
- [Lawrence Lessig on open source AI risks](https://www.transformernews.ai/p/lawrence-lessig-open-source-ai-risks)
- [Podcast: The Promise and Peril of Open Source AI with Elizabeth Seger and Jeffrey Ladish](https://www.humanetech.com/podcast/the-promise-and-peril-of-open-source-ai-with-elizabeth-seger-and-jeffrey-ladish)
- [Dependency (XKCD comic)](https://xkcd.com/2347/)
- [Mozilla's new framework for AI openness and innovation](https://blog.mozilla.org/en/mozilla/ai/new-framework-for-ai-openness-and-innovation/)
- [Meta's AI language model LLaMA leaked online](https://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse)
- [The tech industry's open source AI definition problem](https://www.technologyreview.com/2024/03/25/1090111/tech-industry-open-source-ai-definition-problem/)
- [New York Times: What to know about open vs. closed software](https://www.nytimes.com/2024/05/29/technology/what-to-know-open-closed-software.html)
- [Stanford CRFM paper on open foundation models](https://crfm.stanford.edu/open-fms/paper.pdf)
- [Open source AI: A regulatory review](https://forum.effectivealtruism.org/posts/vCpgHCFzS3xaio2Lm/open-source-ai-a-regulatory-review)
- [Vox article on open source AI risks and benefits](https://www.vox.com/future-perfect/2024/2/2/24058484/open-source-artificial-intelligence-ai-risk-meta-llama-2-chatgpt-openai-deepfake)
- [Ajeya Cotra on open source AI](https://x.com/ajeya_cotra/status/1772859785639285211)
- [The definitive story of "Information wants to be free"](https://medium.com/backchannel/the-definitive-story-of-information-wants-to-be-free-a8d95427641c)
- [UK Government's INSPECT AI project](https://ukgovernmentbeis.github.io/inspect_ai/)
- [NTIA receives over 300 comments on open-weight AI models](https://www.ntia.gov/federal-register-notice/2024/ntia-receives-more-300-comments-open-weight-ai-models)
- [Mozilla Foundation: Technical readout of Columbia convening on openness and AI](https://foundation.mozilla.org/en/research/library/technical-readout-columbia-convening-on-openness-and-ai/)

*Let us know if we missed any resources and we'll add them.*

## Transcript

*Coming soon!*

*Note that this transcript will be **machine-generated**, by a model which makes frequent mistakes and sometimes hallucinates entire sentences. Please check with the original audio before using this transcript to quote our guest.*

{% image "bazaar-5.png" "The Cathedral and the Bazaar" %}

